{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/Faze1/input/dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_with_number_inside( data,\n",
    "                                    column_range_starts : int = 0,\n",
    "                                    column_range_ends : int = None,\n",
    "                                    seperator = None):\n",
    "        \"\"\"\n",
    "        Converts cells with type String contains a series of numbers separated with spaces to a Dictionary and Gives it back.\n",
    "        \"\"\"\n",
    "        start = column_range_starts\n",
    "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends  #Columns\n",
    "        # Split string and convert to uint8 numpy array\n",
    "        new_data = {}\n",
    "        if isinstance( data , pd.DataFrame ) :\n",
    "            for i in range( data.shape[0] ) :\n",
    "                temp_new_data = []\n",
    "                for j in range( start, end ) :\n",
    "                    # for each cell\n",
    "                    # Any exception should be modify by column_range_starts and column_range_ends!\n",
    "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
    "                    temp_new_data.append(cells_real_values)\n",
    "                new_data[i] = temp_new_data\n",
    "\n",
    "            return new_data\n",
    "        else:\n",
    "            if isinstance( data , np.array ) :\n",
    "                pass\n",
    "            else:\n",
    "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save images\n",
    "face_directory = 'data/output/face_directory/'\n",
    "non_face_directory = 'data/output/non_face/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row in corresponds to an image\n",
    "image_size = (48, 48)  # dimensions of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# loop to process images\n",
    "for index, row in data_pix.items():\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
    "\n",
    "    # In face_recognition, the image should be in rgb even if it's grayscale\n",
    "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
    "\n",
    "    # Detect faces in the image using face_recognition\n",
    "    face_locations = face_recognition.face_locations(image_rgb, model='cnn')  # using CNN model\n",
    "\n",
    "    # Process each face found\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image_array[top:bottom, left:right]  # Cropping the grayscale image directly\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(face_locations) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_face_folder = os.listdir('/content/data/face_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_face_folder = os.listdir('/content/data/non_face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(in_face_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_face_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r '/content/face_directory.zip' '/content/data/face_directory/'\n",
    "!zip -r '/content/non_face.zip' '/content/data/non_face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the image size correctly\n",
    "image_size = (48, 48)  # height, width\n",
    "\n",
    "# Directories to save images\n",
    "face_directory = 'data/Faze1/output/newapproch/'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "# Example loop to process images (replace data_pix.items() with your actual image data source)\n",
    "for index, row in data_pix.items():  # replace with actual data fetching method\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])  # Only two dimensions for grayscale\n",
    "\n",
    "    # No need to convert to grayscale since the image is already in grayscale\n",
    "    gray = image_array\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.01, minNeighbors=6, minSize=(20, 20), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Process each face found\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_image = gray[y:y+h, x:x+w]  # Crop from the grayscale image\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(faces) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), gray)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "# Define the image size\n",
    "image_size = (48, 48)  # height, width\n",
    "\n",
    "# Directories to save images\n",
    "face_directory = 'data/Faze1/output/newapproch/'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# Example loop to process images (replace data_pix.items() with your actual image data source)\n",
    "for index, row in data_pix.items():  # replace with actual data fetching method\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
    "    # In face_recognition, the image should be in rgb even if it's grayscale\n",
    "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
    "    # Detect faces in the image using face_recognition\n",
    "    face_locations = face_recognition.face_locations(image_rgb)\n",
    "    # Process each face found\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image_rgb[top:bottom, left:right]\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(face_locations) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the image size correctly\n",
    "image_size = (48, 48)  # height, width\n",
    "\n",
    "# Directories to save images\n",
    "face_directory = 'data/Faze1/output/newapproch/'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# loop to process images\n",
    "for index, row in data_pix.items():\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
    "\n",
    "    # In face_recognition, the image should be in rgb even if it's grayscale\n",
    "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
    "\n",
    "    # Detect faces in the image using face_recognition\n",
    "    face_locations = face_recognition.face_locations(image_rgb, model='cnn')  # using CNN model\n",
    "\n",
    "    # Process each face found\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image_array[top:bottom, left:right]  # Cropping the grayscale image directly\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(face_locations) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model for facial landmarks\n",
    "predictor_path = \"path/to/shape_predictor_68_face_landmarks.dat\"\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread(\"path/to/image.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_detector(gray)\n",
    "\n",
    "for face in faces:\n",
    "    landmarks = landmark_predictor(gray, face)\n",
    "    landmarks_points = []\n",
    "    for n in range(0, 68):  # Dlib provides coordinates for 68 landmarks\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        landmarks_points.append((x, y))\n",
    "        # draw the landmarks on the image\n",
    "        cv2.circle(image, (x, y), 2, (255, 0, 0), -1)\n",
    "\n",
    "    # Applying Delaunay triangulation\n",
    "    rect = (0, 0, image.shape[1], image.shape[0])\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    subdiv.insert(landmarks_points)\n",
    "    triangles = subdiv.getTriangleList()\n",
    "\n",
    "    # Draw triangles\n",
    "    for t in triangles:\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "        cv2.line(image, pt1, pt2, (0, 255, 0), 1)\n",
    "        cv2.line(image, pt2, pt3, (0, 255, 0), 1)\n",
    "        cv2.line(image, pt3, pt1, (0, 255, 0), 1)\n",
    "\n",
    "# Display the image with landmarks and triangles\n",
    "cv2.imshow('Output', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save(data_row, img_dir, img_size=(48, 48)):\n",
    "        \"\"\"Converts pixel strings to image and saves to the respective directory.\"\"\"\n",
    "        \n",
    "        # Split string and convert to uint8 numpy array\n",
    "        pixels = np.array(data_row[' pixels'].split(), dtype='uint8')\n",
    "        try:\n",
    "            # Reshape into image\n",
    "            image = pixels.reshape(img_size)\n",
    "        except ValueError:\n",
    "            print(f\"Error reshaping image: {img_size} may not be the right dimensions.\")\n",
    "            return False\n",
    "        # Create a PIL image\n",
    "        img = Image.fromarray(image, 'L')  # 'L' for grayscale\n",
    "        # Define file path\n",
    "        file_path = os.path.join(img_dir, f\"{data_row.name}.png\")\n",
    "        # Save image\n",
    "        img.save(file_path)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/italojs/facial-landmarks-recognition.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import Images, Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory to store CSVs, grouped by emotion labels\n",
    "base_csv_dir = 'data/Faze1/output/CSVs'\n",
    "base_image_dir = 'data/Faze1/output/Pics'\n",
    "labels = data['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for each label\n",
    "directories = Utilities.create_directories(base_image_dir, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each image in the dataframe\n",
    "for index, row in data.iterrows():\n",
    "    if not Images.save(row, directories[row['emotion']]):\n",
    "        print(f\"Failed to process and save image at index {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for each label\n",
    "directories = Utilities.create_directories(base_csv_dir, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by emotion and save each subset into its corresponding directory\n",
    "for label in labels:\n",
    "    # Filter data for the current label\n",
    "    subset = data[data['emotion'] == label]\n",
    "    # Define file path\n",
    "    file_path = os.path.join(directories[label], f'data_label_{label}.csv')\n",
    "    # Save subset to CSV\n",
    "    subset.to_csv(file_path, index=False)\n",
    "    print(f\"Data for label {label} saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exampel\n",
    "test = pd.read_csv('data/Faze1/output/CSVs/6/data_label_6.csv')\n",
    "test.head(), test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize drawing and face mesh tools\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('path/to/your/image.jpg')\n",
    "\n",
    "# Convert the image to RGB format (OpenCV uses BGR)\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create the face mesh object\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # Analyze the image\n",
    "    results = face_mesh.process(rgb_image)\n",
    "\n",
    "    # Extract landmarks if faces are found\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Loop through each landmark\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                # Get landmark x and y coordinates\n",
    "                landmark_x = landmark.x\n",
    "                landmark_y = landmark.y\n",
    "\n",
    "                # You can store or process these coordinates here\n",
    "                print(f\"Landmark ({landmark.landmark_type}) coordinates: ({landmark_x}, {landmark_y})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from PIL import Image\n",
    "\n",
    "# Path to directory containing images\n",
    "image_directory = 'path/to/your/image/directory'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def plot_delaunay(points, delaunay, ax):\n",
    "    for simplex in delaunay.simplices:\n",
    "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "\n",
    "def detect_faces_and_triangulate(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    detections = detector(img, 1)\n",
    "    for k, d in enumerate(detections):\n",
    "        shape = predictor(img, d)\n",
    "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
    "        delaunay = Delaunay(points)\n",
    "        plot_delaunay(points, delaunay, ax)    \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for image_file in os.listdir(image_directory):\n",
    "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        detect_faces_and_triangulate(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from PIL import Image\n",
    "\n",
    "# Path to directory containing images\n",
    "image_directory = 'path/to/your/image/directory'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def plot_delaunay(points, delaunay, ax):\n",
    "    for simplex in delaunay.simplices:\n",
    "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "\n",
    "\n",
    "def get_delaunay_for_part(points, part_indices):\n",
    "    \"\"\"\n",
    "    Get the Delaunay triangulation for a specific part of the face.\n",
    "\n",
    "    Args:\n",
    "        points (np.array): 68 facial landmarks points.\n",
    "        part_indices (list): Indices of the points that belong to the specific part of the face.\n",
    "\n",
    "    Returns:\n",
    "        Delaunay: Delaunay triangulation for the specific part of the face.\n",
    "    \"\"\"\n",
    "    part_points = points[part_indices]\n",
    "    return Delaunay(part_points)  \n",
    "\n",
    "\n",
    "def detect_faces_and_triangulate_parts(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    detections = detector(img, 1)\n",
    "    for k, d in enumerate(detections):\n",
    "        shape = predictor(img, d)\n",
    "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
    "\n",
    "        # Define the indices of facial landmarks for each part of the face\n",
    "        eye_indices = np.arange(36, 48)\n",
    "        lip_indices = np.arange(48, 68)\n",
    "\n",
    "        # Get the Delaunay triangulation for each part of the face\n",
    "        eye_delaunay = get_delaunay_for_part(points, eye_indices)\n",
    "        lip_delaunay = get_delaunay_for_part(points, lip_indices)\n",
    "\n",
    "        # Plot Delaunay triangulations\n",
    "        plot_delaunay(points, eye_delaunay, ax)\n",
    "        plot_delaunay(points, lip_delaunay, ax)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for image_file in os.listdir(image_directory):\n",
    "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        detect_faces_and_triangulate_parts(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface.xml')\n",
    "\n",
    "def detect_faces(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Return the number of faces detected\n",
    "    return len(faces)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "num_faces = detect_faces(image_path)\n",
    "\n",
    "if num_faces > 0:\n",
    "    print(f\"Image contains {num_faces} faces\")\n",
    "else:\n",
    "    print(\"No faces detected in image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image(image_path, has_face):\n",
    "    num_faces = detect_faces(image_path)\n",
    "    return num_faces == has_face  # True if face count matches the requirement\n",
    "\n",
    "# Example usage: Filter for images with at least one face\n",
    "filtered_images = [image for image in image_paths if filter_image(image, True)]\n",
    "\n",
    "print(\"Paths to images with at least one face:\")\n",
    "for path in filtered_images:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
