{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize drawing and face mesh tools\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('path/to/your/image.jpg')\n",
    "\n",
    "# Convert the image to RGB format (OpenCV uses BGR)\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create the face mesh object\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    # Analyze the image\n",
    "    results = face_mesh.process(rgb_image)\n",
    "\n",
    "    # Extract landmarks if faces are found\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Loop through each landmark\n",
    "            for landmark in face_landmarks.landmark:\n",
    "                # Get landmark x and y coordinates\n",
    "                landmark_x = landmark.x\n",
    "                landmark_y = landmark.y\n",
    "\n",
    "                # You can store or process these coordinates here\n",
    "                print(f\"Landmark ({landmark.landmark_type}) coordinates: ({landmark_x}, {landmark_y})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from PIL import Image\n",
    "\n",
    "# Path to directory containing images\n",
    "image_directory = 'path/to/your/image/directory'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def plot_delaunay(points, delaunay, ax):\n",
    "    for simplex in delaunay.simplices:\n",
    "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "\n",
    "def detect_faces_and_triangulate(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    detections = detector(img, 1)\n",
    "    for k, d in enumerate(detections):\n",
    "        shape = predictor(img, d)\n",
    "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
    "        delaunay = Delaunay(points)\n",
    "        plot_delaunay(points, delaunay, ax)    \n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for image_file in os.listdir(image_directory):\n",
    "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        detect_faces_and_triangulate(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import Delaunay\n",
    "from PIL import Image\n",
    "\n",
    "# Path to directory containing images\n",
    "image_directory = 'path/to/your/image/directory'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def plot_delaunay(points, delaunay, ax):\n",
    "    for simplex in delaunay.simplices:\n",
    "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
    "\n",
    "\n",
    "def get_delaunay_for_part(points, part_indices):\n",
    "    \"\"\"\n",
    "    Get the Delaunay triangulation for a specific part of the face.\n",
    "\n",
    "    Args:\n",
    "        points (np.array): 68 facial landmarks points.\n",
    "        part_indices (list): Indices of the points that belong to the specific part of the face.\n",
    "\n",
    "    Returns:\n",
    "        Delaunay: Delaunay triangulation for the specific part of the face.\n",
    "    \"\"\"\n",
    "    part_points = points[part_indices]\n",
    "    return Delaunay(part_points)  \n",
    "\n",
    "\n",
    "def detect_faces_and_triangulate_parts(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = np.array(img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.imshow(img)\n",
    "\n",
    "    detections = detector(img, 1)\n",
    "    for k, d in enumerate(detections):\n",
    "        shape = predictor(img, d)\n",
    "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
    "\n",
    "        # Define the indices of facial landmarks for each part of the face\n",
    "        eye_indices = np.arange(36, 48)\n",
    "        lip_indices = np.arange(48, 68)\n",
    "\n",
    "        # Get the Delaunay triangulation for each part of the face\n",
    "        eye_delaunay = get_delaunay_for_part(points, eye_indices)\n",
    "        lip_delaunay = get_delaunay_for_part(points, lip_indices)\n",
    "\n",
    "        # Plot Delaunay triangulations\n",
    "        plot_delaunay(points, eye_delaunay, ax)\n",
    "        plot_delaunay(points, lip_delaunay, ax)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for image_file in os.listdir(image_directory):\n",
    "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        detect_faces_and_triangulate_parts(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface.xml')\n",
    "\n",
    "def detect_faces(image_path):\n",
    "    # Read the image\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Return the number of faces detected\n",
    "    return len(faces)\n",
    "\n",
    "# Example usage\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "num_faces = detect_faces(image_path)\n",
    "\n",
    "if num_faces > 0:\n",
    "    print(f\"Image contains {num_faces} faces\")\n",
    "else:\n",
    "    print(\"No faces detected in image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image(image_path, has_face):\n",
    "    num_faces = detect_faces(image_path)\n",
    "    return num_faces == has_face  # True if face count matches the requirement\n",
    "\n",
    "# Example usage: Filter for images with at least one face\n",
    "filtered_images = [image for image in image_paths if filter_image(image, True)]\n",
    "\n",
    "print(\"Paths to images with at least one face:\")\n",
    "for path in filtered_images:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
