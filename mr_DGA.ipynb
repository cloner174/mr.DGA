{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloner174/mr.DGA/blob/main/mr_DGA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJYnS3FsVFMf",
        "outputId": "ebb3c09a-ca5c-4207-a312-c5def8c89674"
      },
      "outputs": [],
      "source": [
        "data_path = \"data/Faze1/input/dataset.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RhO6p4EVkXw",
        "outputId": "bd0f0b20-5141-4325-c0f3-d76a7ee769d4"
      },
      "outputs": [],
      "source": [
        "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ERViRFYkVkRQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nEa91traVkGo"
      },
      "outputs": [],
      "source": [
        "def strings_with_number_inside( data,\n",
        "                                    column_range_starts : int = 0,\n",
        "                                    column_range_ends : int = None,\n",
        "                                    seperator = None):\n",
        "        \"\"\"\n",
        "        Converts cells with type String contains a series of numbers separated with spaces to a Dictionary and Gives it back.\n",
        "        \"\"\"\n",
        "        start = column_range_starts\n",
        "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends  #Columns\n",
        "        # Split string and convert to uint8 numpy array\n",
        "        new_data = {}\n",
        "        if isinstance( data , pd.DataFrame ) :\n",
        "            for i in range( data.shape[0] ) :\n",
        "                temp_new_data = []\n",
        "                for j in range( start, end ) :\n",
        "                    # for each cell\n",
        "                    # Any exception should be modify by column_range_starts and column_range_ends!\n",
        "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
        "                    temp_new_data.append(cells_real_values)\n",
        "                new_data[i] = temp_new_data\n",
        "\n",
        "            return new_data\n",
        "        else:\n",
        "            if isinstance( data , np.array ) :\n",
        "                pass\n",
        "            else:\n",
        "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E62uOvrCV2UZ"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "csv_path = 'data/Faze1/input/dataset.csv'\n",
        "data = pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv('data/output/data-pix2.csv', index= False, compression = {'method': 'zip', 'compresslevel': 8 })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xvkreRmvV3nH"
      },
      "outputs": [],
      "source": [
        "# Path to save images\n",
        "face_directory = 'data/output/face_directory/'\n",
        "non_face_directory = 'data/output/non_face/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M2wasgIVWRMe"
      },
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_pix_df = pd.DataFrame(data_pix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'to_csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_pix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/output/data-pix.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, comprees \u001b[38;5;241m=\u001b[39m s)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_csv'"
          ]
        }
      ],
      "source": [
        "data_pix.to_csv('data/output/data-pix.csv', index= False, comprees = s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2304"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "48*48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpBqTo4QVjch",
        "outputId": "aa2afaca-209e-4906-b863-8af99abec25e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack((image_array,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Detect faces in the image using face_recognition\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcnn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# using CNN model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Process each face found\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face_location \u001b[38;5;129;01min\u001b[39;00m face_locations:\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/face_recognition/api.py:119\u001b[0m, in \u001b[0;36mface_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03mReturns an array of bounding boxes of human faces in a image\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m:return: A list of tuples of found face locations in css (top, right, bottom, left) order\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, model)]\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/face_recognition/api.py:103\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03mReturns an array of bounding boxes of human faces in a image\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m:return: A list of dlib 'rect' objects of found face locations\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcnn_face_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m face_detector(img, number_of_times_to_upsample)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define the image size\n",
        "image_size = (48, 48)  # height, width\n",
        "\n",
        "# Ensure directories exist\n",
        "os.makedirs(face_directory, exist_ok=True)\n",
        "os.makedirs(non_face_directory, exist_ok=True)\n",
        "\n",
        "# loop to process images\n",
        "for index, row in data_pix.items():\n",
        "    # Convert the row to a grayscale image\n",
        "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
        "\n",
        "    # In face_recognition, the image should be in rgb even if it's grayscale\n",
        "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
        "\n",
        "    # Detect faces in the image using face_recognition\n",
        "    face_locations = face_recognition.face_locations(image_rgb, model='cnn')  # using CNN model\n",
        "\n",
        "    # Process each face found\n",
        "    for face_location in face_locations:\n",
        "        top, right, bottom, left = face_location\n",
        "        face_image = image_array[top:bottom, left:right]  # Cropping the grayscale image directly\n",
        "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
        "\n",
        "    # If no faces are detected, save the full image to the non-face directory\n",
        "    if len(face_locations) == 0:\n",
        "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "\n",
        "print(\"Face cropping and saving completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "avf_Tr8uXUD0"
      },
      "outputs": [],
      "source": [
        "in_face_folder = os.listdir('/content/data/face_directory')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lQRQZpMhXd8t"
      },
      "outputs": [],
      "source": [
        "non_face_folder = os.listdir('/content/data/non_face')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewnlWIQFXaTE",
        "outputId": "a81bf233-e776-4e04-c0cc-09273d7ab3a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31519"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(in_face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EACMp2dDXcxr",
        "outputId": "b134b5db-78a5-45fd-92b5-b0f0a5602275"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4368"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(non_face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VndlEpXZYIs1"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/face_directory.zip' '/content/data/face_directory/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VlsbvyzYq9V"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/non_face.zip' '/content/data/non_face'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX_gLRPSalm4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO7wMre02RdbdEaKNGU4OR9",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
