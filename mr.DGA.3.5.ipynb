{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-00jCytRIh"
      },
      "outputs": [],
      "source": [
        "#!apt install cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maUbNV0ot4Ao"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cloner174/mr.DGA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WO_ypx9tmfS"
      },
      "outputs": [],
      "source": [
        "%cd mr.DGA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI8dW6YRtRIi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FWciRMdtRIj"
      },
      "outputs": [],
      "source": [
        "# path to data\n",
        "\n",
        "data_path = 'data/input/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHWwyQxquzGb"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "\n",
        "name_of_batches = os.listdir(data_path)\n",
        "data_batches = []\n",
        "for any_batch_name in name_of_batches :\n",
        "    \n",
        "    path_to_this_batch = os.path.join(data_path, any_batch_name)\n",
        "    temp_batch = pd.read_csv(path_to_this_batch, compression='zip')\n",
        "    data_batches.append(temp_batch)\n",
        "\n",
        "data = pd.concat(data_batches, axis=0, ignore_index=True)\n",
        "#data = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rye62totRIj"
      },
      "outputs": [],
      "source": [
        "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib face_recognition mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI2BNyvAtRIk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRcEBTl8tRIk"
      },
      "outputs": [],
      "source": [
        "def strings_with_number_inside( data,\n",
        "                                    column_range_starts : int = 0,\n",
        "                                    column_range_ends : int = None,\n",
        "                                    seperator = None):\n",
        "        start = column_range_starts\n",
        "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends\n",
        "        new_data = {}\n",
        "        if isinstance( data , pd.DataFrame ) :\n",
        "            for i in range( data.shape[0] ) :\n",
        "                temp_new_data = []\n",
        "                for j in range( start, end ) :\n",
        "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
        "                    temp_new_data.append(cells_real_values)\n",
        "                new_data[i] = temp_new_data\n",
        "\n",
        "            return new_data\n",
        "        else:\n",
        "            if isinstance( data , np.array ) :\n",
        "                pass\n",
        "            else:\n",
        "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx_dPicntRIl"
      },
      "outputs": [],
      "source": [
        "# path to save images\n",
        "\n",
        "face_directory = 'data/output/pic/face'\n",
        "non_face_directory = 'data/output/pic/not_face/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVcatN_ltRIl"
      },
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG47b9eytRIm"
      },
      "outputs": [],
      "source": [
        "# each row corresponds to an image\n",
        "image_size = (48, 48)  #dimensions of image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECXZde8vW6EC"
      },
      "outputs": [],
      "source": [
        "#   #       # #   #   #       # ##   #       # ##   #       # ##   #       # ##   #       # ##   #       # #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ojoOZ1XUPr",
        "outputId": "7b048a8e-fe63-466f-b58b-608387fa0c03"
      },
      "outputs": [],
      "source": [
        "print('path to faces folder: ' ,face_directory,'\\n', 'path to non face folder : ' ,non_face_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO_7LQYnXw4S"
      },
      "outputs": [],
      "source": [
        "#path_to_your_haarcascade_face_model_from_opencv\n",
        "\n",
        "path_to_haarcascade_face_model = 'models/openCV/haarcascade_frontalface_default.xml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07FXvMZuW3qk"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(path_to_haarcascade_face_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClT2N8ZSVxj",
        "outputId": "0e97d6b2-380c-4788-b47c-a4faae483678"
      },
      "outputs": [],
      "source": [
        "os.makedirs(face_directory, exist_ok=True)\n",
        "os.makedirs(non_face_directory, exist_ok=True)\n",
        "\n",
        "# loop to process images\n",
        "for index, row in data_pix.items():\n",
        "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
        "    faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.1, minNeighbors=5)\n",
        "    #face_recognition, needs image in rgb even if its gray\n",
        "    if len(faces) == 0:\n",
        "      cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "    else:\n",
        "        image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
        "        face_locations = face_recognition.face_locations(image_rgb, model='cnn')  #CNN model\n",
        "        for face_location in face_locations:\n",
        "          top, right, bottom, left = face_location\n",
        "          face_image = image_array[top:bottom, left:right]  #cropping\n",
        "          cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
        "        if len(face_locations) == 0:\n",
        "          cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "\n",
        "print(\"Face cropping and saving completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M7aE9AvKZw3",
        "outputId": "b5b73c6b-9d69-4619-a191-dd092b0b6d0a"
      },
      "outputs": [],
      "source": [
        "face_folder = os.listdir(face_directory)\n",
        "non_face_folder = os.listdir(non_face_directory)\n",
        "\n",
        "\n",
        "print('Number of pictures with good face that have been detected by model : ',len(face_folder))\n",
        "print('Number of pictures without any face detected :' , len(non_face_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZJws_UuO8q3",
        "outputId": "01a94475-8639-4f5c-eaee-ae80eba16344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(face_folder)+ len(non_face_folder) == data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT-kIMvcc7aR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "images_emo_map = {}\n",
        "for any_ in face_folder :\n",
        "  temp_path = re.search('\\d+', any_)\n",
        "  temp_num = int(temp_path.group())\n",
        "  images_emo_map[any_] = {}\n",
        "  images_emo_map[any_]['path'] = os.path.join(face_directory, any_)\n",
        "  images_emo_map[any_]['emotion'] = data.loc[temp_num, 'emotion']\n",
        "  images_emo_map[any_]['iloc'] = temp_num\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwu5wYlFc7Tz",
        "outputId": "edf14dfd-1b0b-463f-c132-1bd053194729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(images_emo_map.keys()) == len(face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qLxIcXQfn1e"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from main import Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOh6mL1BtRIr"
      },
      "outputs": [],
      "source": [
        "base_image_dir = 'data/output/pic'\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xNLvooGtRIr"
      },
      "outputs": [],
      "source": [
        "# directories for each label\n",
        "directories = Utilities.create_directories(base_image_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET1odPaAg9bK",
        "outputId": "f742e545-dbcd-42fe-bc06-4ab4073d0ba0"
      },
      "outputs": [],
      "source": [
        "directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22K6R1VXtRIr"
      },
      "outputs": [],
      "source": [
        "# Process each image in the dataframe\n",
        "for index, row in directories.items():\n",
        "   for images_name in face_folder :\n",
        "     if images_emo_map[images_name]['emotion'] == index :\n",
        "      subprocess.call(['mv', images_emo_map[images_name]['path'], row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W20lbhrRkOut",
        "outputId": "bd1d795f-8f97-4635-da44-220fedc3515b"
      },
      "outputs": [],
      "source": [
        "c = 0\n",
        "for indx, any_ in directories.items():\n",
        "  temp_listdir = os.listdir(any_)\n",
        "  print(f'the number of valid images with emotion {indx} is :', len(temp_listdir))\n",
        "  c += len(temp_listdir)\n",
        "print('\\n --> ',c)\n",
        "print( '-->' ,c == len(face_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FfkxewylhvN"
      },
      "outputs": [],
      "source": [
        "valid_rows = []\n",
        "for indx in images_emo_map.keys():\n",
        "\n",
        "  valid_rows.append(images_emo_map[indx]['iloc'])\n",
        "len(valid_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaSzI6j4lYKH",
        "outputId": "03aa9e61-5fb4-448e-cec0-9de38dcbf29d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8194, 2)"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_valid = data.iloc[valid_rows,:]\n",
        "\n",
        "data_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXQ77uS_mRQP"
      },
      "outputs": [],
      "source": [
        "base_image_csv = 'data/output/csv'\n",
        "os.makedirs(base_image_csv, exist_ok=True)\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gm4U7ZWtRIs",
        "outputId": "66aa7036-ecce-4b30-f128-19357fdba0bb"
      },
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "    subset = data_valid[data_valid['emotion'] == label]\n",
        "    print(f'\\n Number of rows of valid data with emotion {label} label : ', subset.shape[0])\n",
        "    file_path = os.path.join(base_image_csv, f'data-valid-label{label}.csv')\n",
        "    subset.to_csv(file_path, index=False)\n",
        "    print(f\"Data for label {label} saved to {file_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
