{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-00jCytRIh"
      },
      "outputs": [],
      "source": [
        "#!apt install cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maUbNV0ot4Ao"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cloner174/mr.DGA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WO_ypx9tmfS"
      },
      "outputs": [],
      "source": [
        "%cd mr.DGA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YI8dW6YRtRIi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0FWciRMdtRIj"
      },
      "outputs": [],
      "source": [
        "# path to data\n",
        "\n",
        "data_path = 'data/input/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aHWwyQxquzGb"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "\n",
        "name_of_batches = os.listdir(data_path)\n",
        "\n",
        "data_batches_path = []\n",
        "for any_batch_name in name_of_batches :\n",
        "    \n",
        "    path_to_this_batch = os.path.join(data_path, any_batch_name)\n",
        "    data_batches_path.append(path_to_this_batch)\n",
        "\n",
        "data_batches_path.sort()\n",
        "\n",
        "data_batches = []\n",
        "for path_to_this_batch in data_batches_path :\n",
        "    \n",
        "    temp_batch = pd.read_csv(path_to_this_batch, compression='zip')\n",
        "    data_batches.append(temp_batch)\n",
        "\n",
        "data = pd.concat(data_batches, axis=0, ignore_index=True)\n",
        "#data = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   emotion                                             pixels\n",
              " 0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              " 1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              " 2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              " 3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              " 4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...,\n",
              " '\\n',\n",
              " (35887, 2))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(), '\\n', data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rye62totRIj"
      },
      "outputs": [],
      "source": [
        "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib mediapipe face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oI2BNyvAtRIk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LRcEBTl8tRIk"
      },
      "outputs": [],
      "source": [
        "def strings_with_number_inside( data,\n",
        "                                    column_range_starts : int = 0,\n",
        "                                    column_range_ends : int = None,\n",
        "                                    seperator = None):\n",
        "        start = column_range_starts\n",
        "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends\n",
        "        new_data = {}\n",
        "        if isinstance( data , pd.DataFrame ) :\n",
        "            for i in range( data.shape[0] ) :\n",
        "                temp_new_data = []\n",
        "                for j in range( start, end ) :\n",
        "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
        "                    temp_new_data.append(cells_real_values)\n",
        "                new_data[i] = temp_new_data\n",
        "\n",
        "            return new_data\n",
        "        else:\n",
        "            if isinstance( data , np.array ) :\n",
        "                pass\n",
        "            else:\n",
        "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jx_dPicntRIl"
      },
      "outputs": [],
      "source": [
        "# path to save images\n",
        "\n",
        "face_directory = 'data/output/pic/face'\n",
        "non_face_directory = 'data/output/pic/not_face/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yG47b9eytRIm"
      },
      "outputs": [],
      "source": [
        "# each row corresponds to an image\n",
        "image_size = (48, 48)  #dimensions of image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECXZde8vW6EC"
      },
      "outputs": [],
      "source": [
        "#   #       # #   #   #       # ##   #       # ##   #       # ##   #       # ##   #       # ##   #       # #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ojoOZ1XUPr",
        "outputId": "7b048a8e-fe63-466f-b58b-608387fa0c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path to faces folder:  data/output/pic/face \n",
            " path to non face folder :  data/output/pic/not_face/\n"
          ]
        }
      ],
      "source": [
        "print('path to faces folder: ' ,face_directory,'\\n', 'path to non face folder : ' ,non_face_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JO_7LQYnXw4S"
      },
      "outputs": [],
      "source": [
        "#path_to_your_haarcascade_face_model_from_opencv\n",
        "\n",
        "path_to_haarcascade_face_model = 'models/openCV/haarcascade_frontalface_default.xml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "07FXvMZuW3qk"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(path_to_haarcascade_face_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClT2N8ZSVxj",
        "outputId": "0e97d6b2-380c-4788-b47c-a4faae483678"
      },
      "outputs": [],
      "source": [
        "os.makedirs(face_directory, exist_ok=True)\n",
        "os.makedirs(non_face_directory, exist_ok=True)\n",
        "\n",
        "# loop to process images\n",
        "for index, row in data_pix.items():\n",
        "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
        "    faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.1, minNeighbors=5)\n",
        "    face_recognition, needs image in rgb even if its gray\n",
        "    if len(faces) == 0:\n",
        "      cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "    else:\n",
        "        image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
        "        face_locations = face_recognition.face_locations(image_rgb, model='cnn')  #CNN model\n",
        "        for face_location in face_recognition:\n",
        "          top, right, bottom, left = face_location\n",
        "          face_image = image_array[top:bottom, left:right]  #cropping\n",
        "          cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
        "        if len(face_locations) == 0:\n",
        "          cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "\n",
        "print(\"Face cropping and saving completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M7aE9AvKZw3",
        "outputId": "b5b73c6b-9d69-4619-a191-dd092b0b6d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of pictures with good face that have been detected by model :  4426\n",
            "Number of pictures without any face detected : 14870\n"
          ]
        }
      ],
      "source": [
        "face_folder = os.listdir(face_directory)\n",
        "non_face_folder = os.listdir(non_face_directory)\n",
        "\n",
        "\n",
        "print('Number of pictures with good face that have been detected by model : ',len(face_folder))\n",
        "print('Number of pictures without any face detected :' , len(non_face_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZJws_UuO8q3",
        "outputId": "01a94475-8639-4f5c-eaee-ae80eba16344"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(face_folder)+ len(non_face_folder) == data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VT-kIMvcc7aR"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "7082",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx:219\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx:227\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/_libs/index.pyx:119\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 7082",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m images_emo_map[any_] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      7\u001b[0m images_emo_map[any_][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(face_directory, any_)\n\u001b[0;32m----> 8\u001b[0m images_emo_map[any_][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtemp_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m images_emo_map[any_][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_num\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1329\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py:1039\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1045\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1342\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py:4236\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4234\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4236\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4239\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
            "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 7082"
          ]
        }
      ],
      "source": [
        "import re\n",
        "images_emo_map = {}\n",
        "for any_ in face_folder :\n",
        "  temp_path = re.search('\\d+', any_)\n",
        "  temp_num = int(temp_path.group())\n",
        "  images_emo_map[any_] = {}\n",
        "  images_emo_map[any_]['path'] = os.path.join(face_directory, any_)\n",
        "  images_emo_map[any_]['emotion'] = data.loc[temp_num, 'emotion']\n",
        "  images_emo_map[any_]['iloc'] = temp_num\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwu5wYlFc7Tz",
        "outputId": "edf14dfd-1b0b-463f-c132-1bd053194729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(images_emo_map.keys()) == len(face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2qLxIcXQfn1e"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from main import Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HOh6mL1BtRIr"
      },
      "outputs": [],
      "source": [
        "base_image_dir = 'data/output/pic'\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1xNLvooGtRIr"
      },
      "outputs": [],
      "source": [
        "# directories for each label\n",
        "directories = Utilities.create_directories(base_image_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET1odPaAg9bK",
        "outputId": "f742e545-dbcd-42fe-bc06-4ab4073d0ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'data/output/pic/0',\n",
              " 6: 'data/output/pic/6',\n",
              " 3: 'data/output/pic/3',\n",
              " 5: 'data/output/pic/5',\n",
              " 4: 'data/output/pic/4',\n",
              " 2: 'data/output/pic/2',\n",
              " 1: 'data/output/pic/1'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "22K6R1VXtRIr"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'emotion'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m directories\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m    \u001b[38;5;28;01mfor\u001b[39;00m images_name \u001b[38;5;129;01min\u001b[39;00m face_folder :\n\u001b[0;32m----> 4\u001b[0m      \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimages_emo_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimages_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m index :\n\u001b[1;32m      5\u001b[0m       subprocess\u001b[38;5;241m.\u001b[39mcall([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmv\u001b[39m\u001b[38;5;124m'\u001b[39m, images_emo_map[images_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m], row])\n",
            "\u001b[0;31mKeyError\u001b[0m: 'emotion'"
          ]
        }
      ],
      "source": [
        "# Process each image in the dataframe\n",
        "for index, row in directories.items():\n",
        "   for images_name in face_folder :\n",
        "     if images_emo_map[images_name]['emotion'] == index :\n",
        "      subprocess.call(['mv', images_emo_map[images_name]['path'], row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W20lbhrRkOut",
        "outputId": "bd1d795f-8f97-4635-da44-220fedc3515b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the number of valid images with emotion 0 is : 0\n",
            "the number of valid images with emotion 6 is : 0\n",
            "the number of valid images with emotion 3 is : 0\n",
            "the number of valid images with emotion 5 is : 0\n",
            "the number of valid images with emotion 4 is : 0\n",
            "the number of valid images with emotion 2 is : 0\n",
            "the number of valid images with emotion 1 is : 0\n",
            "\n",
            " -->  0\n",
            "--> False\n"
          ]
        }
      ],
      "source": [
        "c = 0\n",
        "for indx, any_ in directories.items():\n",
        "  temp_listdir = os.listdir(any_)\n",
        "  print(f'the number of valid images with emotion {indx} is :', len(temp_listdir))\n",
        "  c += len(temp_listdir)\n",
        "print('\\n --> ',c)\n",
        "print( '-->' ,c == len(face_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8FfkxewylhvN"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'iloc'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m valid_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx \u001b[38;5;129;01min\u001b[39;00m images_emo_map\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m----> 4\u001b[0m   valid_rows\u001b[38;5;241m.\u001b[39mappend(\u001b[43mimages_emo_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miloc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mlen\u001b[39m(valid_rows)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'iloc'"
          ]
        }
      ],
      "source": [
        "valid_rows = []\n",
        "for indx in images_emo_map.keys():\n",
        "\n",
        "  valid_rows.append(images_emo_map[indx]['iloc'])\n",
        "len(valid_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaSzI6j4lYKH",
        "outputId": "03aa9e61-5fb4-448e-cec0-9de38dcbf29d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8194, 2)"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_valid = data.iloc[valid_rows,:]\n",
        "\n",
        "data_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXQ77uS_mRQP"
      },
      "outputs": [],
      "source": [
        "base_image_csv = 'data/output/csv'\n",
        "os.makedirs(base_image_csv, exist_ok=True)\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gm4U7ZWtRIs",
        "outputId": "66aa7036-ecce-4b30-f128-19357fdba0bb"
      },
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "    subset = data_valid[data_valid['emotion'] == label]\n",
        "    print(f'\\n Number of rows of valid data with emotion {label} label : ', subset.shape[0])\n",
        "    file_path = os.path.join(base_image_csv, f'data-valid-label{label}.csv')\n",
        "    subset.to_csv(file_path, index=False)\n",
        "    print(f\"Data for label {label} saved to {file_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
