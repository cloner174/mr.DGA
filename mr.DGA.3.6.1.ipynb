{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-00jCytRIh"
      },
      "outputs": [],
      "source": [
        "#!apt install cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maUbNV0ot4Ao"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cloner174/mr.DGA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WO_ypx9tmfS"
      },
      "outputs": [],
      "source": [
        "%cd mr.DGA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YI8dW6YRtRIi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0FWciRMdtRIj"
      },
      "outputs": [],
      "source": [
        "# path to data\n",
        "\n",
        "data_path = 'data/input/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aHWwyQxquzGb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_batches_path : \n",
            " ['data/input/data_batch1.csv', 'data/input/data_batch2.csv', 'data/input/data_batch3.csv', 'data/input/data_batch4.csv', 'data/input/data_batch5.csv', 'data/input/data_batch6.csv', 'data/input/data_batch7.csv', 'data/input/data_batch8.csv']\n",
            "Start to Concatation the Data Batches \n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "\n",
        "name_of_batches = os.listdir(data_path)\n",
        "\n",
        "data_batches_path = []\n",
        "for any_batch_name in name_of_batches :\n",
        "    \n",
        "    path_to_this_batch = os.path.join(data_path, any_batch_name)\n",
        "    data_batches_path.append(path_to_this_batch)\n",
        "\n",
        "data_batches_path.sort()\n",
        "print('data_batches_path : \\n' , data_batches_path)\n",
        "data_batches = []\n",
        "for path_to_this_batch in data_batches_path :\n",
        "    \n",
        "    temp_batch = pd.read_csv(path_to_this_batch, compression='zip')\n",
        "    data_batches.append(temp_batch)\n",
        "\n",
        "print('Start to Concatation the Data Batches ')\n",
        "\n",
        "data = pd.concat(data_batches, axis=0, ignore_index=True)\n",
        "#data = pd.read_csv(data_path)\n",
        "print('Concatation the Data Batches was Seccessfully Done! ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   emotion                                             pixels\n",
              " 0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
              " 1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
              " 2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
              " 3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
              " 4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...,\n",
              " '\\n',\n",
              " (35887, 2))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(), '\\n', data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rye62totRIj"
      },
      "outputs": [],
      "source": [
        "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib mediapipe #face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oI2BNyvAtRIk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LRcEBTl8tRIk"
      },
      "outputs": [],
      "source": [
        "def strings_with_number_inside( data,\n",
        "                                    column_range_starts : int = 0,\n",
        "                                    column_range_ends : int = None,\n",
        "                                    seperator = None):\n",
        "        start = column_range_starts\n",
        "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends\n",
        "        new_data = {}\n",
        "        if isinstance( data , pd.DataFrame ) :\n",
        "            for i in range( data.shape[0] ) :\n",
        "                temp_new_data = []\n",
        "                for j in range( start, end ) :\n",
        "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
        "                    temp_new_data.append(cells_real_values)\n",
        "                new_data[i] = temp_new_data\n",
        "\n",
        "            return new_data\n",
        "        else:\n",
        "            if isinstance( data , np.array ) :\n",
        "                pass\n",
        "            else:\n",
        "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_pixels = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jx_dPicntRIl"
      },
      "outputs": [],
      "source": [
        "# path to save images\n",
        "\n",
        "face_directory = 'data/output/pic/face-from-3.6.1/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yG47b9eytRIm"
      },
      "outputs": [],
      "source": [
        "# each row corresponds to an image\n",
        "image_size = (48, 48)  #dimensions of image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECXZde8vW6EC"
      },
      "outputs": [],
      "source": [
        "#   #       # #   #   #       # ##   #       # ##   #       # ##   #       # ##   #       # ##   #       # #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ojoOZ1XUPr",
        "outputId": "7b048a8e-fe63-466f-b58b-608387fa0c03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path to faces folder:  data/output/pic/face-from-3.6.1/ \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('path to faces folder: ' ,face_directory,'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JO_7LQYnXw4S"
      },
      "outputs": [],
      "source": [
        "#path_to_your_haarcascade_face_model_from_opencv\n",
        "\n",
        "path_to_haarcascade_face_model = 'models/openCV/haarcascade_frontalface_default.xml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "07FXvMZuW3qk"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(path_to_haarcascade_face_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClT2N8ZSVxj",
        "outputId": "0e97d6b2-380c-4788-b47c-a4faae483678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Face cropping and saving completed.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(face_directory, exist_ok=True)\n",
        "\n",
        "# loop to process images\n",
        "for index, row in data_pixels.items():\n",
        "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
        "    faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.1, minNeighbors=5)\n",
        "    if len(faces) == 0:\n",
        "      pass\n",
        "    else:\n",
        "        for face in faces:\n",
        "          cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face)\n",
        "\n",
        "print(\"Face cropping and saving completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M7aE9AvKZw3",
        "outputId": "b5b73c6b-9d69-4619-a191-dd092b0b6d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of pictures with good face that have been detected by model :  8707\n"
          ]
        }
      ],
      "source": [
        "face_folder = os.listdir(face_directory)\n",
        "\n",
        "print('Number of pictures with good face that have been detected by model : ',len(face_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VT-kIMvcc7aR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "images_emo_map = {}\n",
        "for any_ in face_folder :\n",
        "  temp_path = re.search('\\d+', any_)\n",
        "  temp_num = int(temp_path.group())\n",
        "  images_emo_map[any_] = {}\n",
        "  images_emo_map[any_]['path'] = os.path.join(face_directory, any_)\n",
        "  images_emo_map[any_]['emotion'] = data.loc[temp_num, 'emotion']\n",
        "  images_emo_map[any_]['iloc'] = temp_num\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwu5wYlFc7Tz",
        "outputId": "edf14dfd-1b0b-463f-c132-1bd053194729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(images_emo_map.keys()) == len(face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2qLxIcXQfn1e"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from main import Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HOh6mL1BtRIr"
      },
      "outputs": [],
      "source": [
        "base_image_dir = 'data/output/pic/from-3.6.1/'\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1xNLvooGtRIr"
      },
      "outputs": [],
      "source": [
        "# directories for each label\n",
        "directories = Utilities.create_directories(base_image_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET1odPaAg9bK",
        "outputId": "f742e545-dbcd-42fe-bc06-4ab4073d0ba0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'data/output/pic/from-3.6.1/0',\n",
              " 2: 'data/output/pic/from-3.6.1/2',\n",
              " 4: 'data/output/pic/from-3.6.1/4',\n",
              " 6: 'data/output/pic/from-3.6.1/6',\n",
              " 3: 'data/output/pic/from-3.6.1/3',\n",
              " 5: 'data/output/pic/from-3.6.1/5',\n",
              " 1: 'data/output/pic/from-3.6.1/1'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "22K6R1VXtRIr"
      },
      "outputs": [],
      "source": [
        "# Process each image in the dataframe\n",
        "for index, row in directories.items():\n",
        "   for images_name in face_folder :\n",
        "     if images_emo_map[images_name]['emotion'] == index :\n",
        "      subprocess.call(['cp', images_emo_map[images_name]['path'], row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W20lbhrRkOut",
        "outputId": "bd1d795f-8f97-4635-da44-220fedc3515b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the number of valid images with emotion 0 is : 1169\n",
            "the number of valid images with emotion 2 is : 948\n",
            "the number of valid images with emotion 4 is : 931\n",
            "the number of valid images with emotion 6 is : 1917\n",
            "the number of valid images with emotion 3 is : 2680\n",
            "the number of valid images with emotion 5 is : 897\n",
            "the number of valid images with emotion 1 is : 165\n",
            "\n",
            " -->  8707\n",
            "--> True\n"
          ]
        }
      ],
      "source": [
        "c = 0\n",
        "for indx, any_ in directories.items():\n",
        "  temp_listdir = os.listdir(any_)\n",
        "  print(f'the number of valid images with emotion {indx} is :', len(temp_listdir))\n",
        "  c += len(temp_listdir)\n",
        "print('\\n --> ',c)\n",
        "print( '-->' ,c == len(face_folder))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8FfkxewylhvN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8707"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_rows = []\n",
        "for indx in images_emo_map.keys():\n",
        "\n",
        "  valid_rows.append(images_emo_map[indx]['iloc'])\n",
        "len(valid_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaSzI6j4lYKH",
        "outputId": "03aa9e61-5fb4-448e-cec0-9de38dcbf29d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8707, 2)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_valid = data.iloc[valid_rows,:]\n",
        "\n",
        "data_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_valid.to_csv('data/output/csv/Data-Valid-from-3.6.1.csv.zip', compression={'method':'zip', 'compresslevel':8})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qXQ77uS_mRQP"
      },
      "outputs": [],
      "source": [
        "base_image_csv = 'data/output/csv/new-from-3.6.1/'\n",
        "os.makedirs(base_image_csv, exist_ok=True)\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gm4U7ZWtRIs",
        "outputId": "66aa7036-ecce-4b30-f128-19357fdba0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Number of rows of valid data with emotion 0 label :  1169\n",
            "Data for label 0 saved to data/output/csv/new-from-3.6.1/data-valid-label0.csv\n",
            "\n",
            " Number of rows of valid data with emotion 2 label :  948\n",
            "Data for label 2 saved to data/output/csv/new-from-3.6.1/data-valid-label2.csv\n",
            "\n",
            " Number of rows of valid data with emotion 4 label :  931\n",
            "Data for label 4 saved to data/output/csv/new-from-3.6.1/data-valid-label4.csv\n",
            "\n",
            " Number of rows of valid data with emotion 6 label :  1917\n",
            "Data for label 6 saved to data/output/csv/new-from-3.6.1/data-valid-label6.csv\n",
            "\n",
            " Number of rows of valid data with emotion 3 label :  2680\n",
            "Data for label 3 saved to data/output/csv/new-from-3.6.1/data-valid-label3.csv\n",
            "\n",
            " Number of rows of valid data with emotion 5 label :  897\n",
            "Data for label 5 saved to data/output/csv/new-from-3.6.1/data-valid-label5.csv\n",
            "\n",
            " Number of rows of valid data with emotion 1 label :  165\n",
            "Data for label 1 saved to data/output/csv/new-from-3.6.1/data-valid-label1.csv\n"
          ]
        }
      ],
      "source": [
        "for label in labels:\n",
        "    subset = data_valid[data_valid['emotion'] == label]\n",
        "    print(f'\\n Number of rows of valid data with emotion {label} label : ', subset.shape[0])\n",
        "    file_path = os.path.join(base_image_csv, f'data-valid-label{label}.csv')\n",
        "    subset.to_csv(file_path, index=False)\n",
        "    print(f\"Data for label {label} saved to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "images_emo_map = []\n",
        "for any_ in face_folder :\n",
        "    temp_path = re.search('\\d+', any_)\n",
        "    temp_num = int(temp_path.group())\n",
        "    col = {\n",
        "        'name': any_,\n",
        "        'path':os.path.join(face_directory, any_),\n",
        "        'emotion' : data.loc[temp_num, 'emotion'],\n",
        "        'iloc' : temp_num\n",
        "    }\n",
        "    images_emo_map.append(col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "images_emo_map = pd.DataFrame( images_emo_map )\n",
        "images_emo_map.to_csv('data/output/csv/images_emo_map.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we Have Two Diffrent Kind of Approach to gather the valid images\n",
        "\n",
        "# Our rest of work will uses this one !"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
