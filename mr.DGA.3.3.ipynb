{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-00jCytRIh"
      },
      "outputs": [],
      "source": [
        "#!apt install cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maUbNV0ot4Ao",
        "outputId": "8d741c0c-a999-409c-908f-1b1e03323ef3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cloner174/mr.DGA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "VXbt0vKYtTgN",
        "outputId": "3cd09759-b8d8-4fa7-9c66-2379dcb9a803"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/new/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WO_ypx9tmfS"
      },
      "outputs": [],
      "source": [
        "%cp '/content/new/MyDrive/Colab Notebooks/data-pix.csv' '/content/mr.DGA/data/Faze1/input'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHb0JYrsuFAe"
      },
      "outputs": [],
      "source": [
        "%mv '/content/mr.DGA/data/Faze1/input/data-pix.csv' '/content/mr.DGA/data/Faze1/input/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI8dW6YRtRIi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FWciRMdtRIj"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/mr.DGA/data/Faze1/input/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHWwyQxquzGb"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "\n",
        "data = pd.read_csv(data_path, compression='zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rye62totRIj",
        "outputId": "b51dc1ca-60bf-43b8-f785-8f83e9d70ea2"
      },
      "outputs": [],
      "source": [
        "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib face_recognition mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI2BNyvAtRIk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRcEBTl8tRIk"
      },
      "outputs": [],
      "source": [
        "def strings_with_number_inside( data,\n",
        "                                    column_range_starts : int = 0,\n",
        "                                    column_range_ends : int = None,\n",
        "                                    seperator = None):\n",
        "        start = column_range_starts\n",
        "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends\n",
        "        new_data = {}\n",
        "        if isinstance( data , pd.DataFrame ) :\n",
        "            for i in range( data.shape[0] ) :\n",
        "                temp_new_data = []\n",
        "                for j in range( start, end ) :\n",
        "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
        "                    temp_new_data.append(cells_real_values)\n",
        "                new_data[i] = temp_new_data\n",
        "\n",
        "            return new_data\n",
        "        else:\n",
        "            if isinstance( data , np.array ) :\n",
        "                pass\n",
        "            else:\n",
        "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx_dPicntRIl"
      },
      "outputs": [],
      "source": [
        "# path to save images\n",
        "face_directory = '/content/data/Faze1/output/face_directory/'\n",
        "non_face_directory = '/content/data/Faze1/output/non_face/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVcatN_ltRIl"
      },
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG47b9eytRIm"
      },
      "outputs": [],
      "source": [
        "# each row in corresponds to an image\n",
        "image_size = (48, 48)  # dimensions of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjhCWp5itRIm",
        "outputId": "907c6aeb-baa1-48db-f67f-3750318b698a"
      },
      "outputs": [],
      "source": [
        "os.makedirs(face_directory, exist_ok=True)\n",
        "os.makedirs(non_face_directory, exist_ok=True)\n",
        "\n",
        "for index, row in data_pix.items():\n",
        "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
        "\n",
        "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
        "\n",
        "    face_locations = face_recognition.face_locations(image_rgb, model='cnn')\n",
        "\n",
        "    for face_location in face_locations:\n",
        "        top, right, bottom, left = face_location\n",
        "        face_image = image_array[top:bottom, left:right]\n",
        "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
        "\n",
        "    if len(face_locations) == 0:\n",
        "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "\n",
        "print(\"face cropping and saving completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8g3IdoXtRIn"
      },
      "outputs": [],
      "source": [
        "in_face_folder = os.listdir(face_directory)\n",
        "non_face_folder = os.listdir(non_face_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDts0rYItRIn",
        "outputId": "8b4486ef-c65d-4c55-e5d9-f13c859932e4"
      },
      "outputs": [],
      "source": [
        "len(in_face_folder), len(non_face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJAs3wW6tRIo"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/face_directory.zip' '/content/data/face_directory/'\n",
        "!zip -r '/content/non_face.zip' '/content/data/non_face'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17LiXX9R07C4"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier('/content/mr.DGA/mr.DGA/models/haarcascade_frontalface_default.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDH_46uHtRIo"
      },
      "outputs": [],
      "source": [
        "\n",
        "def detect_faces(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "    return len(faces)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soXBhD310G78"
      },
      "outputs": [],
      "source": [
        "invali_trues = []\n",
        "for any_ in in_face_folder :\n",
        "  temp_path = os.path.join(face_directory, any_)\n",
        "  temp_len = detect_faces(temp_path)\n",
        "  if temp_len == 0 :\n",
        "    invali_trues.append(any_)\n",
        "  else:\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BgduBUw0GzU",
        "outputId": "5459ac19-8913-4eef-f1e0-3de08d08410a"
      },
      "outputs": [],
      "source": [
        "len(invali_trues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpo0SU0ztRIo"
      },
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z-NbzAdtRIp"
      },
      "outputs": [],
      "source": [
        "#%pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9s2qJGPtRIq"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "predictor_path = \"/content/mr.DGA/models/shape_predictor_68_face_landmarks.dat\"\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "landmark_predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "image = cv2.imread(\"path/to/image.jpg\")\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = face_detector(gray)\n",
        "\n",
        "for face in faces:\n",
        "    landmarks = landmark_predictor(gray, face)\n",
        "    landmarks_points = []\n",
        "    for n in range(0, 68):\n",
        "        x = landmarks.part(n).x\n",
        "        y = landmarks.part(n).y\n",
        "        landmarks_points.append((x, y))\n",
        "        cv2.circle(image, (x, y), 2, (255, 0, 0), -1)\n",
        "\n",
        "    rect = (0, 0, image.shape[1], image.shape[0])\n",
        "    subdiv = cv2.Subdiv2D(rect)\n",
        "    subdiv.insert(landmarks_points)\n",
        "    triangles = subdiv.getTriangleList()\n",
        "\n",
        "    for t in triangles:\n",
        "        pt1 = (t[0], t[1])\n",
        "        pt2 = (t[2], t[3])\n",
        "        pt3 = (t[4], t[5])\n",
        "        cv2.line(image, pt1, pt2, (0, 255, 0), 1)\n",
        "        cv2.line(image, pt2, pt3, (0, 255, 0), 1)\n",
        "        cv2.line(image, pt3, pt1, (0, 255, 0), 1)\n",
        "\n",
        "cv2.imshow('Output', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qvb_PUKtRIq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save(data_row, img_dir, img_size=(48, 48)):\n",
        "\n",
        "        pixels = np.array(data_row[' pixels'].split(), dtype='uint8')\n",
        "        try:\n",
        "            image = pixels.reshape(img_size)\n",
        "        except ValueError:\n",
        "            print(f\"Error reshaping image: {img_size} may not be the right dimensions.\")\n",
        "            return False\n",
        "        img = Image.fromarray(image, 'L')  # 'L' for grayscale\n",
        "        file_path = os.path.join(img_dir, f\"{data_row.name}.png\")\n",
        "        img.save(file_path)\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjQSCbr1tRIq"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/italojs/facial-landmarks-recognition.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfdFsFj8tRIq"
      },
      "outputs": [],
      "source": [
        "from main import Images, Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOh6mL1BtRIr"
      },
      "outputs": [],
      "source": [
        "# Base directory to store CSVs, grouped by emotion labels\n",
        "base_csv_dir = 'data/Faze1/output/CSVs'\n",
        "base_image_dir = 'data/Faze1/output/Pics'\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xNLvooGtRIr"
      },
      "outputs": [],
      "source": [
        "# Create directories for each label\n",
        "directories = Utilities.create_directories(base_image_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22K6R1VXtRIr"
      },
      "outputs": [],
      "source": [
        "# Process each image in the dataframe\n",
        "for index, row in data.iterrows():\n",
        "    if not Images.save(row, directories[row['emotion']]):\n",
        "        print(f\"Failed to process and save image at index {index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0flht2sbtRIr"
      },
      "outputs": [],
      "source": [
        "# Create directories for each label\n",
        "directories = Utilities.create_directories(base_csv_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gm4U7ZWtRIs"
      },
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "\n",
        "    subset = data[data['emotion'] == label]\n",
        "    file_path = os.path.join(directories[label], f'data_label_{label}.csv')\n",
        "    subset.to_csv(file_path, index=False)\n",
        "    print(f\"Data for label {label} saved to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwJIzZoKtRIs"
      },
      "outputs": [],
      "source": [
        "#example\n",
        "test = pd.read_csv('data/Faze1/output/CSVs/6/data_label_6.csv')\n",
        "test.head(), test.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeyEGzmLtRIs",
        "outputId": "43738993-ce66-40ad-b54d-1fdc552a86cd"
      },
      "outputs": [],
      "source": [
        "%pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tny4GjhLtRIs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "with mp_face_mesh.FaceMesh(\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5) as face_mesh:\n",
        "\n",
        "    results = face_mesh.process(rgb_image)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            for landmark in face_landmarks.landmark:\n",
        "                landmark_x = landmark.x\n",
        "                landmark_y = landmark.y\n",
        "\n",
        "                print(f\"Landmark ({landmark.landmark_type}) coordinates: ({landmark_x}, {landmark_y})\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpoVKR7QtRIt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import Delaunay\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "image_directory = ''\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def plot_delaunay(points, delaunay, ax):\n",
        "    for simplex in delaunay.simplices:\n",
        "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
        "\n",
        "def detect_faces_and_triangulate(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.imshow(img)\n",
        "\n",
        "    detections = detector(img, 1)\n",
        "    for k, d in enumerate(detections):\n",
        "        shape = predictor(img, d)\n",
        "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
        "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
        "        delaunay = Delaunay(points)\n",
        "        plot_delaunay(points, delaunay, ax)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for image_file in os.listdir(image_directory):\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(image_directory, image_file)\n",
        "        detect_faces_and_triangulate(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpF6leR4tRIt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import Delaunay\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = ''\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def plot_delaunay(points, delaunay, ax):\n",
        "    for simplex in delaunay.simplices:\n",
        "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
        "\n",
        "def get_delaunay_for_part(points, part_indices):\n",
        "    part_points = points[part_indices]\n",
        "    return Delaunay(part_points)\n",
        "\n",
        "def detect_faces_and_triangulate_parts(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.imshow(img)\n",
        "\n",
        "    detections = detector(img, 1)\n",
        "    for k, d in enumerate(detections):\n",
        "        shape = predictor(img, d)\n",
        "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
        "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
        "\n",
        "        eye_indices = np.arange(36, 48)\n",
        "        lip_indices = np.arange(48, 68)\n",
        "\n",
        "        eye_delaunay = get_delaunay_for_part(points, eye_indices)\n",
        "        lip_delaunay = get_delaunay_for_part(points, lip_indices)\n",
        "\n",
        "        plot_delaunay(points, eye_delaunay, ax)\n",
        "        plot_delaunay(points, lip_delaunay, ax)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for image_file in os.listdir(image_directory):\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(image_directory, image_file)\n",
        "        detect_faces_and_triangulate_parts(image_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
