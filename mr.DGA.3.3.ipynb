{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-00jCytRIh"
      },
      "outputs": [],
      "source": [
        "#!apt install cmake"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cloner174/mr.DGA.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maUbNV0ot4Ao",
        "outputId": "8d741c0c-a999-409c-908f-1b1e03323ef3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mr.DGA'...\n",
            "remote: Enumerating objects: 254, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 254 (delta 10), reused 20 (delta 5), pack-reused 227\u001b[K\n",
            "Receiving objects: 100% (254/254), 234.32 MiB | 19.61 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "Updating files: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/new/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "VXbt0vKYtTgN",
        "outputId": "3cd09759-b8d8-4fa7-9c66-2379dcb9a803"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-803a8ec1accb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/new/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp '/content/new/MyDrive/Colab Notebooks/data-pix.csv' '/content/mr.DGA/data/Faze1/input'"
      ],
      "metadata": {
        "id": "3WO_ypx9tmfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mv '/content/mr.DGA/data/Faze1/input/data-pix.csv' '/content/mr.DGA/data/Faze1/input/dataset.csv'"
      ],
      "metadata": {
        "id": "KHb0JYrsuFAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI8dW6YRtRIi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FWciRMdtRIj"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/mr.DGA/data/Faze1/input/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "\n",
        "data = pd.read_csv(data_path, compression='zip')"
      ],
      "metadata": {
        "id": "aHWwyQxquzGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rye62totRIj",
        "outputId": "b51dc1ca-60bf-43b8-f785-8f83e9d70ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=171be800b484787923d08a0fdf5bdaa8cdd258da66ca9883bea3c57d2aebb8fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib face_recognition mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI2BNyvAtRIk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRcEBTl8tRIk"
      },
      "outputs": [],
      "source": [
        "def strings_with_number_inside( data,\n",
        "                                    column_range_starts : int = 0,\n",
        "                                    column_range_ends : int = None,\n",
        "                                    seperator = None):\n",
        "        start = column_range_starts\n",
        "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends\n",
        "        new_data = {}\n",
        "        if isinstance( data , pd.DataFrame ) :\n",
        "            for i in range( data.shape[0] ) :\n",
        "                temp_new_data = []\n",
        "                for j in range( start, end ) :\n",
        "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
        "                    temp_new_data.append(cells_real_values)\n",
        "                new_data[i] = temp_new_data\n",
        "\n",
        "            return new_data\n",
        "        else:\n",
        "            if isinstance( data , np.array ) :\n",
        "                pass\n",
        "            else:\n",
        "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx_dPicntRIl"
      },
      "outputs": [],
      "source": [
        "# path to save images\n",
        "face_directory = '/content/data/Faze1/output/face_directory/'\n",
        "non_face_directory = '/content/data/Faze1/output/non_face/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVcatN_ltRIl"
      },
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG47b9eytRIm"
      },
      "outputs": [],
      "source": [
        "# each row in corresponds to an image\n",
        "image_size = (48, 48)  # dimensions of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjhCWp5itRIm",
        "outputId": "907c6aeb-baa1-48db-f67f-3750318b698a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face cropping and saving completed.\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(face_directory, exist_ok=True)\n",
        "os.makedirs(non_face_directory, exist_ok=True)\n",
        "\n",
        "for index, row in data_pix.items():\n",
        "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
        "\n",
        "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
        "\n",
        "    face_locations = face_recognition.face_locations(image_rgb, model='cnn')\n",
        "\n",
        "    for face_location in face_locations:\n",
        "        top, right, bottom, left = face_location\n",
        "        face_image = image_array[top:bottom, left:right]\n",
        "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
        "\n",
        "    if len(face_locations) == 0:\n",
        "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
        "\n",
        "print(\"face cropping and saving completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8g3IdoXtRIn"
      },
      "outputs": [],
      "source": [
        "in_face_folder = os.listdir(face_directory)\n",
        "non_face_folder = os.listdir(non_face_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDts0rYItRIn",
        "outputId": "8b4486ef-c65d-4c55-e5d9-f13c859932e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31519, 4368)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(in_face_folder), len(non_face_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgU1vT4ftRIn"
      },
      "outputs": [],
      "source": [
        "filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRdLNKDZtRIn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJAs3wW6tRIo"
      },
      "outputs": [],
      "source": [
        "!zip -r '/content/face_directory.zip' '/content/data/face_directory/'\n",
        "!zip -r '/content/non_face.zip' '/content/data/non_face'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier('/content/mr.DGA/mr.DGA/models/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "17LiXX9R07C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDH_46uHtRIo"
      },
      "outputs": [],
      "source": [
        "\n",
        "def detect_faces(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "    return len(faces)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invali_trues = []\n",
        "for any_ in in_face_folder :\n",
        "  temp_path = os.path.join(face_directory, any_)\n",
        "  temp_len = detect_faces(temp_path)\n",
        "  if temp_len == 0 :\n",
        "    invali_trues.append(any_)\n",
        "  else:\n",
        "    continue"
      ],
      "metadata": {
        "id": "soXBhD310G78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(invali_trues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BgduBUw0GzU",
        "outputId": "5459ac19-8913-4eef-f1e0-3de08d08410a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29289"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpo0SU0ztRIo"
      },
      "outputs": [],
      "source": [
        "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z-NbzAdtRIp"
      },
      "outputs": [],
      "source": [
        "#%pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9s2qJGPtRIq"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "predictor_path = \"/content/mr.DGA/models/shape_predictor_68_face_landmarks.dat\"\n",
        "face_detector = dlib.get_frontal_face_detector()\n",
        "landmark_predictor = dlib.shape_predictor(predictor_path)\n",
        "\n",
        "image = cv2.imread(\"path/to/image.jpg\")\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "faces = face_detector(gray)\n",
        "\n",
        "for face in faces:\n",
        "    landmarks = landmark_predictor(gray, face)\n",
        "    landmarks_points = []\n",
        "    for n in range(0, 68):\n",
        "        x = landmarks.part(n).x\n",
        "        y = landmarks.part(n).y\n",
        "        landmarks_points.append((x, y))\n",
        "        cv2.circle(image, (x, y), 2, (255, 0, 0), -1)\n",
        "\n",
        "    rect = (0, 0, image.shape[1], image.shape[0])\n",
        "    subdiv = cv2.Subdiv2D(rect)\n",
        "    subdiv.insert(landmarks_points)\n",
        "    triangles = subdiv.getTriangleList()\n",
        "\n",
        "    for t in triangles:\n",
        "        pt1 = (t[0], t[1])\n",
        "        pt2 = (t[2], t[3])\n",
        "        pt3 = (t[4], t[5])\n",
        "        cv2.line(image, pt1, pt2, (0, 255, 0), 1)\n",
        "        cv2.line(image, pt2, pt3, (0, 255, 0), 1)\n",
        "        cv2.line(image, pt3, pt1, (0, 255, 0), 1)\n",
        "\n",
        "cv2.imshow('Output', image)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qvb_PUKtRIq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save(data_row, img_dir, img_size=(48, 48)):\n",
        "\n",
        "        pixels = np.array(data_row[' pixels'].split(), dtype='uint8')\n",
        "        try:\n",
        "            image = pixels.reshape(img_size)\n",
        "        except ValueError:\n",
        "            print(f\"Error reshaping image: {img_size} may not be the right dimensions.\")\n",
        "            return False\n",
        "        img = Image.fromarray(image, 'L')  # 'L' for grayscale\n",
        "        file_path = os.path.join(img_dir, f\"{data_row.name}.png\")\n",
        "        img.save(file_path)\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjQSCbr1tRIq"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/italojs/facial-landmarks-recognition.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfdFsFj8tRIq"
      },
      "outputs": [],
      "source": [
        "from main import Images, Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOh6mL1BtRIr"
      },
      "outputs": [],
      "source": [
        "# Base directory to store CSVs, grouped by emotion labels\n",
        "base_csv_dir = 'data/Faze1/output/CSVs'\n",
        "base_image_dir = 'data/Faze1/output/Pics'\n",
        "labels = data['emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xNLvooGtRIr"
      },
      "outputs": [],
      "source": [
        "# Create directories for each label\n",
        "directories = Utilities.create_directories(base_image_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22K6R1VXtRIr"
      },
      "outputs": [],
      "source": [
        "# Process each image in the dataframe\n",
        "for index, row in data.iterrows():\n",
        "    if not Images.save(row, directories[row['emotion']]):\n",
        "        print(f\"Failed to process and save image at index {index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0flht2sbtRIr"
      },
      "outputs": [],
      "source": [
        "# Create directories for each label\n",
        "directories = Utilities.create_directories(base_csv_dir, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gm4U7ZWtRIs"
      },
      "outputs": [],
      "source": [
        "for label in labels:\n",
        "\n",
        "    subset = data[data['emotion'] == label]\n",
        "    file_path = os.path.join(directories[label], f'data_label_{label}.csv')\n",
        "    subset.to_csv(file_path, index=False)\n",
        "    print(f\"Data for label {label} saved to {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwJIzZoKtRIs"
      },
      "outputs": [],
      "source": [
        "#example\n",
        "test = pd.read_csv('data/Faze1/output/CSVs/6/data_label_6.csv')\n",
        "test.head(), test.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeyEGzmLtRIs",
        "outputId": "43738993-ce66-40ad-b54d-1fdc552a86cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.13 protobuf-4.25.3 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "%pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tny4GjhLtRIs"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "with mp_face_mesh.FaceMesh(\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5,\n",
        "    min_tracking_confidence=0.5) as face_mesh:\n",
        "\n",
        "    results = face_mesh.process(rgb_image)\n",
        "\n",
        "    if results.multi_face_landmarks:\n",
        "        for face_landmarks in results.multi_face_landmarks:\n",
        "            for landmark in face_landmarks.landmark:\n",
        "                landmark_x = landmark.x\n",
        "                landmark_y = landmark.y\n",
        "\n",
        "                print(f\"Landmark ({landmark.landmark_type}) coordinates: ({landmark_x}, {landmark_y})\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpoVKR7QtRIt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import Delaunay\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "image_directory = ''\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def plot_delaunay(points, delaunay, ax):\n",
        "    for simplex in delaunay.simplices:\n",
        "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
        "\n",
        "def detect_faces_and_triangulate(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.imshow(img)\n",
        "\n",
        "    detections = detector(img, 1)\n",
        "    for k, d in enumerate(detections):\n",
        "        shape = predictor(img, d)\n",
        "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
        "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
        "        delaunay = Delaunay(points)\n",
        "        plot_delaunay(points, delaunay, ax)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for image_file in os.listdir(image_directory):\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(image_directory, image_file)\n",
        "        detect_faces_and_triangulate(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpF6leR4tRIt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import Delaunay\n",
        "from PIL import Image\n",
        "\n",
        "image_directory = ''\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def plot_delaunay(points, delaunay, ax):\n",
        "    for simplex in delaunay.simplices:\n",
        "        ax.plot(points[simplex, 0], points[simplex, 1], 'k-')\n",
        "\n",
        "def get_delaunay_for_part(points, part_indices):\n",
        "    part_points = points[part_indices]\n",
        "    return Delaunay(part_points)\n",
        "\n",
        "def detect_faces_and_triangulate_parts(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = np.array(img)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.imshow(img)\n",
        "\n",
        "    detections = detector(img, 1)\n",
        "    for k, d in enumerate(detections):\n",
        "        shape = predictor(img, d)\n",
        "        points = np.array([[p.x, p.y] for p in shape.parts()])\n",
        "        ax.scatter(points[:, 0], points[:, 1], c='r', s=10)\n",
        "\n",
        "        eye_indices = np.arange(36, 48)\n",
        "        lip_indices = np.arange(48, 68)\n",
        "\n",
        "        eye_delaunay = get_delaunay_for_part(points, eye_indices)\n",
        "        lip_delaunay = get_delaunay_for_part(points, lip_indices)\n",
        "\n",
        "        plot_delaunay(points, eye_delaunay, ax)\n",
        "        plot_delaunay(points, lip_delaunay, ax)\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "for image_file in os.listdir(image_directory):\n",
        "    if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        image_path = os.path.join(image_directory, image_file)\n",
        "        detect_faces_and_triangulate_parts(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyO9qbeJtRIt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrPAKg8gtRIu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IHw6ijFtRIu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RWaKTIctRIu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr-NjDOFtRIv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}