{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imutils opencv-python dlib opencv-python-headless pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_with_number_inside( data,\n",
    "                                    column_range_starts : int = 0,\n",
    "                                    column_range_ends : int = None,\n",
    "                                    seperator = None):\n",
    "        \"\"\"\n",
    "        Converts cells with type String contains a series of numbers separated with spaces to a Dictionary and Gives it back.\n",
    "        \"\"\"\n",
    "        start = column_range_starts\n",
    "        end = int( data.shape[1] ) if column_range_ends is None else column_range_ends  #Columns        \n",
    "        # Split string and convert to uint8 numpy array\n",
    "        new_data = {}\n",
    "        if isinstance( data , pd.DataFrame ) :\n",
    "            for i in range( data.shape[0] ) :\n",
    "                temp_new_data = []\n",
    "                for j in range( start, end ) :\n",
    "                    # for each cell\n",
    "                    # Any exception should be modify by column_range_starts and column_range_ends!\n",
    "                    cells_real_values = np.array(data.iloc[i, j].split(sep = seperator), dtype='uint8')\n",
    "                    temp_new_data.append(cells_real_values)\n",
    "                new_data[i] = temp_new_data\n",
    "            \n",
    "            return new_data\n",
    "        else:\n",
    "            if isinstance( data , np.array ) :\n",
    "                pass\n",
    "            else:\n",
    "                raise TypeError( \" data just could be  PandasDataFrame  or  NumpyArray  ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "csv_path = 'data/Faze1/input/dataset.csv'\n",
    "data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row in corresponds to an image\n",
    "image_size = (48, 48)  # dimensions of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save images\n",
    "face_directory = 'data/Faze1/output/newapproch'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pix = strings_with_number_inside(data, column_range_starts = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row in the CSV to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face cropping and saving completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the image size correctly\n",
    "image_size = (48, 48)  # height, width\n",
    "\n",
    "# Directories to save images\n",
    "face_directory = 'data/Faze1/output/newapproch/'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# Load the pre-trained face detection model\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "# Example loop to process images (replace data_pix.items() with your actual image data source)\n",
    "for index, row in data_pix.items():  # replace with actual data fetching method\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])  # Only two dimensions for grayscale\n",
    "\n",
    "    # No need to convert to grayscale since the image is already in grayscale\n",
    "    gray = image_array\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.01, minNeighbors=6, minSize=(20, 20), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Process each face found\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_image = gray[y:y+h, x:x+w]  # Crop from the grayscale image\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(faces) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), gray)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting face_recognition\n",
      "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/lib/python3/dist-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in /home/user/.local/lib/python3.11/site-packages (from face_recognition) (19.24.4)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from face_recognition) (1.24.2)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from face_recognition) (10.3.0)\n",
      "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=b62621fc9a4a274eacdcfaf641ef4dc28de3a190c413c047506fec57bb2d70e5\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models, face_recognition\n",
      "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face cropping and saving completed.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "\n",
    "# Define the image size\n",
    "image_size = (48, 48)  # height, width\n",
    "\n",
    "# Directories to save images\n",
    "face_directory = 'data/Faze1/output/newapproch/'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# Example loop to process images (replace data_pix.items() with your actual image data source)\n",
    "for index, row in data_pix.items():  # replace with actual data fetching method\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
    "    # In face_recognition, the image should be in rgb even if it's grayscale\n",
    "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
    "    # Detect faces in the image using face_recognition\n",
    "    face_locations = face_recognition.face_locations(image_rgb)\n",
    "    # Process each face found\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image_rgb[top:bottom, left:right]\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(face_locations) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the image size correctly\n",
    "image_size = (48, 48)  # height, width\n",
    "\n",
    "# Directories to save images\n",
    "face_directory = 'data/Faze1/output/newapproch/'\n",
    "non_face_directory = 'data/Faze1/output/newapproch/na/'\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(face_directory, exist_ok=True)\n",
    "os.makedirs(non_face_directory, exist_ok=True)\n",
    "\n",
    "# loop to process images\n",
    "for index, row in data_pix.items():\n",
    "    # Convert the row to a grayscale image\n",
    "    image_array = np.array(row, dtype=np.uint8).reshape(image_size[0], image_size[1])\n",
    "\n",
    "    # In face_recognition, the image should be in rgb even if it's grayscale\n",
    "    image_rgb = np.stack((image_array,) * 3, axis=-1)\n",
    "\n",
    "    # Detect faces in the image using face_recognition\n",
    "    face_locations = face_recognition.face_locations(image_rgb, model='cnn')  # using CNN model\n",
    "\n",
    "    # Process each face found\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image_array[top:bottom, left:right]  # Cropping the grayscale image directly\n",
    "        cv2.imwrite(os.path.join(face_directory, f'face_{index}.jpg'), face_image)\n",
    "\n",
    "    # If no faces are detected, save the full image to the non-face directory\n",
    "    if len(face_locations) == 0:\n",
    "        cv2.imwrite(os.path.join(non_face_directory, f'non_face_{index}.jpg'), image_array)\n",
    "\n",
    "print(\"Face cropping and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model for facial landmarks\n",
    "predictor_path = \"path/to/shape_predictor_68_face_landmarks.dat\"\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Load an image\n",
    "image = cv2.imread(\"path/to/image.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = face_detector(gray)\n",
    "\n",
    "for face in faces:\n",
    "    landmarks = landmark_predictor(gray, face)\n",
    "    landmarks_points = []\n",
    "    for n in range(0, 68):  # Dlib provides coordinates for 68 landmarks\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        landmarks_points.append((x, y))\n",
    "        # draw the landmarks on the image\n",
    "        cv2.circle(image, (x, y), 2, (255, 0, 0), -1)\n",
    "\n",
    "    # Applying Delaunay triangulation\n",
    "    rect = (0, 0, image.shape[1], image.shape[0])\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    subdiv.insert(landmarks_points)\n",
    "    triangles = subdiv.getTriangleList()\n",
    "\n",
    "    # Draw triangles\n",
    "    for t in triangles:\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "        cv2.line(image, pt1, pt2, (0, 255, 0), 1)\n",
    "        cv2.line(image, pt2, pt3, (0, 255, 0), 1)\n",
    "        cv2.line(image, pt3, pt1, (0, 255, 0), 1)\n",
    "\n",
    "# Display the image with landmarks and triangles\n",
    "cv2.imshow('Output', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Read image and create blob\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "modelFile = \"data/models/face_detector_advance/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"data/models/face_detector_advance/deploy.prototxt.txt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "for index, row in data_pix.items():\n",
    "    image = np.array(row, dtype=np.uint8).reshape(image_size)\n",
    "    h, w = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    # Detect faces\n",
    "    net.setInput(blob)\n",
    "    faces = net.forward()\n",
    "\n",
    "    # Draw faces\n",
    "    for i in range(faces.shape[2]):\n",
    "        confidence = faces[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "            cv2.rectangle(image, (x, y), (x1, y1), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Detected Faces\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save(data_row, img_dir, img_size=(48, 48)):\n",
    "        \"\"\"Converts pixel strings to image and saves to the respective directory.\"\"\"\n",
    "        \n",
    "        # Split string and convert to uint8 numpy array\n",
    "        pixels = np.array(data_row[' pixels'].split(), dtype='uint8')\n",
    "        try:\n",
    "            # Reshape into image\n",
    "            image = pixels.reshape(img_size)\n",
    "        except ValueError:\n",
    "            print(f\"Error reshaping image: {img_size} may not be the right dimensions.\")\n",
    "            return False\n",
    "        # Create a PIL image\n",
    "        img = Image.fromarray(image, 'L')  # 'L' for grayscale\n",
    "        # Define file path\n",
    "        file_path = os.path.join(img_dir, f\"{data_row.name}.png\")\n",
    "        # Save image\n",
    "        img.save(file_path)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/italojs/facial-landmarks-recognition.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python-headless pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Faze1/input/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from main import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.loc[0, ' pixels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first image\n",
    "pixel_values = np.array(data[' pixels'].iloc[0].split(), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2304/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = pixel_values.reshape(48, 48)\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images.plot(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory to store images, grouped by emotion labels\n",
    "base_image_dir = 'data/Faze1/output/Pics'\n",
    "labels = data['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for each label\n",
    "directories = Utilities.create_directories(base_image_dir, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each image in the dataframe\n",
    "for index, row in data.iterrows():\n",
    "    if not Images.save(row, directories[row['emotion']]):\n",
    "        print(f\"Failed to process and save image at index {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory to store CSVs, grouped by emotion labels\n",
    "base_csv_dir = 'data/Faze1/output/CSVs'\n",
    "labels = data['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for each label\n",
    "directories = Utilities.create_directories(base_csv_dir, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by emotion and save each subset into its corresponding directory\n",
    "for label in labels:\n",
    "    # Filter data for the current label\n",
    "    subset = data[data['emotion'] == label]\n",
    "    # Define file path\n",
    "    file_path = os.path.join(directories[label], f'data_label_{label}.csv')\n",
    "    # Save subset to CSV\n",
    "    subset.to_csv(file_path, index=False)\n",
    "    print(f\"Data for label {label} saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/Faze1/output/CSVs/6/data_label_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(), test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
